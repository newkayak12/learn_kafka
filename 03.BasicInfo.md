# 기본 개념

## 카프카 브로커/ 클러스터/ 주키퍼

브로커는 클라이언트와 데이터를 주고 받기 위해서 사용하는 주체이자, 데이터를 분산 저장하여 장애가 발생하더라도 안전하게 사용할 수 있도록 도와주는 애플리케이션이다.
하나의 서버에는 하나의 카프카 브로커 프로세스가 실행된다. 보통 운영에서는 3대 이상의 브로커 서버를 1개의 클러스터로 묶어서 운영한다. 클러스터로 묶인 브로커들은
프로듀서가 보낸 데이터를 안전하게 분산하고 저장하고 복제하는 역할을 수행한다.

### 데이터 저장/ 전송
프로듀서로부터 데이터를 전달받으면 카프카 브로커는 프로듀서가 요청한 토픽의 파티션에 데이터를 저장하고 컨슈머가 데이터를 요청하면 파티션에 저장한 데이터를 전달한다.
프로듀서로부터 전달된 데이터는 파일 시스템에 저장된다.

```shell
bash-5.2# ls /tmp/kafka-logs ## /config/server.properties의 log.dir 옵션에 정의한 디렉토리에 데이터를 저장한다.
                             ## 토픽 이름과 파티션 번호의 조합으로 하위 디렉토리를 생성하여 데이터를 저장한다.

__consumer_offsets-0   __consumer_offsets-17  __consumer_offsets-25  __consumer_offsets-33  __consumer_offsets-41  __consumer_offsets-5       hello.kafka-3
__consumer_offsets-1   __consumer_offsets-18  __consumer_offsets-26  __consumer_offsets-34  __consumer_offsets-42  __consumer_offsets-6       log-start-offset-checkpoint
__consumer_offsets-10  __consumer_offsets-19  __consumer_offsets-27  __consumer_offsets-35  __consumer_offsets-43  __consumer_offsets-7       meta.properties
__consumer_offsets-11  __consumer_offsets-2   __consumer_offsets-28  __consumer_offsets-36  __consumer_offsets-44  __consumer_offsets-8       recovery-point-offset-checkpoint
__consumer_offsets-12  __consumer_offsets-20  __consumer_offsets-29  __consumer_offsets-37  __consumer_offsets-45  __consumer_offsets-9       replication-offset-checkpoint
__consumer_offsets-13  __consumer_offsets-21  __consumer_offsets-3   __consumer_offsets-38  __consumer_offsets-46  cleaner-offset-checkpoint  verify-test-0
__consumer_offsets-14  __consumer_offsets-22  __consumer_offsets-30  __consumer_offsets-39  __consumer_offsets-47  hello.kafka-0
__consumer_offsets-15  __consumer_offsets-23  __consumer_offsets-31  __consumer_offsets-4   __consumer_offsets-48  hello.kafka-1
__consumer_offsets-16  __consumer_offsets-24  __consumer_offsets-32  __consumer_offsets-40  __consumer_offsets-49  hello.kafka-2

bash-5.2# ls hello.kafka-0  ##hello.kafka 토픽의 0번 파티션에 존재하는 데이터를 확인할 수 있다. 메시지와 메타데이터를 저장한다.
                            ##index는 메시지 오프셋을 인덱싱한 정보를 담는 파일이다. timeindex는 메시지에 포함된 timestamp를 기준으로 인덱싱한 정보가 담겨있다.
                            ##timestamp값은 브로커가 적재한 데이터를 삭제하거나 압축하는 데에 사용한다.

00000000000000000000.index  00000000000000000000.log  00000000000000000000.timeindex  leader-epoch-checkpoint
```

카프카는 메모리나 DB에 저장하지 않으며 따로 캐시 메모리를 구현하여 사용하지도 않는다. 일반적으로 파일 시스템으느 다루기 편하만 지속적으로 입출력할 경우 메모리에 올려서
사용하는 것보다 느리기 때문이다. 그러나 카프카는 페이지 캐시(PageCache)를 사용해서 디스크 입출력 속도를 높여서 이 문제를 해결했다. 페이지 캐시란 OS에서
파일 입출력 성능 향상을 위해서 만들어 놓은 메모리 영역을 뜻한다. 한 번 읽은 파일의 내용은 메모리의 페이지 캐시 영역에 저장시킨다. 추후 동일한 파일의 접근이
발생하면 디스크에서 읽지 않고 메모리에서 직접 읽는다. 페이지 캐시가 없다면 동작 속도는 현저히 느려졌을 것이다. 페이징을 직접 구현하고, 지속적으로 변경되는 데이터
때문에 가비지 컬렉션이 자주 일어나 속도가 느려졌을 것이다. 이러한 이유 때문에 굳이 브로커 실행에 힙을 크게 설정할 필요가 없다.


### 데이터 복제, 싱크
데이터 복제(replication)는 카프카를 장해 허용 시스템(fault tolerant system)으로 동작하도록 하는 원동력이다. 복제의 이유는 클러스터로 묶인 브로커 중 일부에
장애가 발생하더라도 데이터를 유실하지 않고 안전하게 사용하기 위함이다.

카프카의 데이터 복제는 파티션 단위로 이뤄진다. 토픽을 생성할 때 파티션의 복제 개수( replication factor )도 함께 설정되는데 직접 옵션을 선택하지 않으면
브로커에 설정된 옵션 값을 따라간다. 복제 개수의 최소 값은 1( 복제를 사용하지 않음 )이고 최댓값은 브로커 개수만큼 설정해서 사용할 수 있다.

복제된 파티션은 leaer - follower로 구성된다. 프로듀서 또는 컨슈머와 직접 통신하는 파티션을 리더라고 지칭하며, 나머지 복제 데이터를 가진 파티션을 팔로워라고 부른다.
팔로워 파티션들은 리터 파티션의 오프셋을 확인하여 현재 자신이 가진 오프셋과 차이가 나는 경우 리더 파티션으로부터 데이터를 가져와서 자신의 파티션에 저장하는데, 이를 
복제(replication)이라고 부른다. 파티션 복제로 인해 나머지 브로커에도 파티션의 데이터가 복제되므로 복제 개수만큼 저장 용량이 증가한다는 단점이 있다. 그러나
복제를 통해서 데이터를 안전하게 사용할 수 있다는 이점 때문에 카프카를 운영할 때 2개 이상의 복제 개수를 것이 중요하다.

만일 카프카 클러스터 중 0번에 장애가 생겨서 브로커가 다운되면 리더 파티션은 지위를 위임하며, 팔로워 중 하나가 이를 넘겨 받는다. 

### 컨트롤러
클러스터의 다수 브로커 중 한 대가 컨트롤러 역할을 한다. 컨트롤러는 다른 브로커들의 상태를 체크하고 브로커가 클러스터에서 빠지는 경우 해당 브로커에 존재하는 리더 파티션을
재할당한다. 카프카는 지속적으로 데이터를 처리해야 하므로 브로커의 상태가 비정상이라면 빠르게 클러스터에서 내보내는 것이 중요하다. 만약 컨트롤러가 행동 불능이 되면
다른 브로커가 위임 받는다.

### 데이터 삭제
카프카는 다른 메시징 플랫폼과 다르게 데이터를 가져가도 토픽의 데이터는 삭제되지 않는다. 또한, 컨슈머나 프로듀서가 데이터 삭제를 요청할 수도 없다. 오직 브로커만이
데이터를 삭제할 수 있다. 데이터 삭제는 파일단위로 이뤄지는데 이 단위를 `LogSegment`라고 부른다. 이 세그먼트에는 다수의 데이터가 들어 있기 때문에 일반적인
DB처럼 특정 데이터를 선별할 수는 없다. 세그먼트는 데이터가 쌓이는 동안 파일 시스템으로 열려 있으며, 카프카 브로커에  `log.segment.bytes` 또는 `log.segment.ms`
옵션이 설정되면 세그먼트 파일이 설정 값에 따라 닫힌다. 너무 작은 값으로 설정하면 열고 닫고가 잦아져서 부하가 발생할 수 있으므로 주의해야 한다. 
닫힌 세그먼트 파일은 `log.retention.bytes` 또는 `log.retention.ms` 옵션에 설정 값이 넘으면 삭제된다. 닫힌 세그먼트 파일을 체크하는 간격은
카프카 브로커의 옵션에 설정된 `log.retention.check.interval.ms`에 따른다.

### 컨슈머 오프셋 저장
컨슈머 그룹은 토픽이 특정 파티션으로부터 데이터를 가져가서 처리하고 이 파티션의 어느 레코드까지 가져갔는지 확인하기 위해서 오프셋을 커밋한다. 커밋한 오프셋은 `__consumer_offsets` 토픽에 저장한다. 
여기에 저장한 오프셋을 토대로 컨슈머 그룹은 다음 레코드를 가져가서 처리한다.

### 코디네이터(coordinator)
클러스터의 다수 브로커 중 한 대는 코디네이터 역할을 수행한다. 코디네이터는 컨슈머 그룹의 상태를 체크하고 파티션을 컨슈머와 매칭되도록 분배하는 역할을 한다. 
컨슈머가 컨슈머 그룹에서 빠지면 매칭되지 않은 파티션을 정상 동작하는 컨슈머로 할당하여 끊임 없이 데이터가 처리되도록 도와준다. 이 과정을 `rebalance`라고 부른다.


여기까지 브로커의 역할이다. 카프카 클러스터에서 주키퍼는 무슨 일을 할까? 주키퍼는 카프카의 메타 데이터를 관리하는 데에 사용된다. 주키퍼 쉘은 `zookeeper-shell.sh`로 실행할 수 있다.
```shell
bash-5.2# ./bin/zookeeper-shell.sh localhost:2181  
## 해당 명령어로 동일 환경에서 실행되는 주키퍼에 접속할 수 있다. 주키퍼 쉘을 통해서 znode를 조회하고 쉉할 수 있다.

# Connecting to localhost:2181
# Welcome to ZooKeeper!
# JLine support is disabled
#
# WATCHER::
#
# WatchedEvent state:SyncConnected type:None path:null

ls /
## root znode 하위 znode를 확인한다. 
#[admin, brokers, cluster, config, consumers, controller, controller_epoch, isr_change_notification, latest_producer_id_block, log_dir_event_notification, zookeeper]

get /brokers/ids/0
## 실습용으로 생성한 카프카 브로커에 대한 정보를 확인한다. 어떤 보안 규칙으로 통신하는지, jmx port 상태 정보, host 정보 등이 포함되어 있다. 
#{
# "listener_security_protocol_map":{
#                                   "PLAINTEXT":"PLAINTEXT"
#                                  },
# "endpoints":["PLAINTEXT://5722ad92016b:9092"],
# "jmx_port":-1,
# "host":"5722ad92016b",
# "timestamp":"1708258479515",
# "port":9092,
# "version":4
# }

get /controller
## 어느 브로커가 컨트롤러인지에 대한 정보를 가져온다.
#{
# "version":1,
# "brokerid":0,
# "timestamp":"1708258479595"
# }

ls /brokers/topics
## 카프카에 저장된 토픽들을 확인한다. `__consumer_offsets`는 카프카 내부에서 컨슈머 오프셋을 저장하기 위한 용도로 사용되는 토픽이다.
#[__consumer_offsets, hello.kafka, verify-test]

```

카프카 클러스터로 묶인 브로커들은 동일한 경로의 주키퍼 경로로 선언해야 같은 브로커 묶음이 된다. 만약 클러스터를 여러 개로 운영하면 한 개의 주키퍼에 다수의
카프카 클러스터를 연결해서 사용할 수도 있다.

## 토픽과 파티션
토픽은 카프카에서 데이터를 구분하기 위해서 사용하는 단위다. 토픽은 1개 이상의 파티션을 소유하고 있다. 파티션에는 프로듀서가 보낸 데이터들이 들어가 저장되는데
이 데이터를 `레코드(record)`라고 한다.
 
파티션은 카프카의 병렬처리의 핵심으로써 그룹으로 묶인 컨슈머들이 레코드를 병렬로 처리할 수 있도록 매칭된다. 컨슈머의 처리량의 한정된 상황에서 많은 레코드를 병렬로 처리하는 
가장 좋은 방법은 컨슈머의 개수를 늘려서 스케일아웃하는 것이다. 컨슈머를 늘리면 파티션도 늘어서 처리량이 증가하는 효과를 볼 수 있다. 파티션은 queue와 비슷하다고
생각하면 쉽다. FIFO 구조 같이 선입선출이 된다. 다만, 일반적인 자료구조로 사용되는 큐는 데이터를 가져가면 (pop) 레코드를 삭제하지만 카프카는 삭제하지 않는다.
파티션의 레코드는 컨슈머가 소비하는 것과 별개로 관리된다. 이러한 특징 떄문에 토픽 레코드는 다양한 목적을 가진 여러 컨슈머 그룹들이 토픽의 데이터를 여러 번 
가져갈 수 있다.

## 토픽 이름 제약 조건
1. 빈 문자열 토픽은 지원하지 않는다.
2. '.', '..'로 생성될 수 없다.
3. 249자 미만으로 생성되야한다.
4. 영어 대/소, 숫자, '.', ',', '_', '-'을 조합해서 생성할 수 있다.
5. `__consumer_offsets`, `__transaction_state`로는 생성할 수 없다.
6. '.', '_'가 동시에 들어가면 이슈가 발생할 수 있으므로 권장하지 않는다.
7. '.'를 '_'로, '_'를 '.'로 바꾼 경우 신규 토픽과 이름이 동일하다면 생성할 수 없다.

### 토픽 장명 예시
- `<환경>.<팀명>.<애플리케이션명>.<메시지타입>` => mrd.marketing-team.sms-platform.json
- `<프로젝트명>.<서비스명>.<환경>.<이벤트명>` => commerce.payment.prd.notification
- `<카프카 클러스터명>.<환경>.<서비스명>.<메시지타입>` => aws-kafka.live.marketing-platform.json

컨벤션을 정하고 따르지 않으면 기술 부채로 남아 훗날 문제가 될 것이다. 따라서 처음부터 컨벤션에 맞춰 잘 작성하는 것이 좋다.

## 레코드
레코드는 타임스탬프, 메시지 키, 메시지 값, 오프셋, 헤더로 구성되어 있다. 프로듀서가 생성한 레코드가 브로커로 전송되면 오프셋과 타임스탬프가 지정되어 저장된다. 
브로커에 한 번 적재된 레코드는 수정할 수 없고 로그 리텐션 기간 또는 용량에 따라서만 삭제된다.

타임 스탬프는 프로듀서에서 해당 레코드가 생성된 시점의 유닉스 타임이 설정된다. 컨슈머는 레코드의 타임스탬프를 토대로 레코드가 언제 생성되었는지 알 수 있다.
다만, 프로듀서가 레코드를 생성할 떄 임의의 타임스탬프 값을 설정할 수 있고, 토픽 설정에 따라 브로커에 적재된 시간(LogAppendTime)으로 설정될 수도 있다는 것에 유의해야 한다.

메시지 키는 메시지 값을 순서대로 처리하거나 메시지 값의 종류를 나타내기 위해서 사용한다. 메시지 키를 사용하면 프로듀서가 토픽에 레코드를 전송할 떄 메시지 키의 해시 값을 토대로 파티션을 지정하게 된다.
즉, 동일한 메시지 키라면 동일 파티션에 들어가는 것이다. 다만, 정확히 어느 파티션에 지정될지 알 수 없고 파티션 개수가 변경되면 메시지 키와 파티션 매칭이 
달라지게 되므로 주의해야 한다. 만약 메시지 키를 사용하지 않으면 프로듀서에서 레코드를 전송할 때 메시지 키를 선언하지 않으면 된다. 선언하지 않으면 `null` 설정된다.
메시지 키가 `null`로 설정된 레코드는 프로듀서 기본 설정 파티셔너에 따라서 파티션에 분배되어 적재된다.

메시지 값에는 실질적으로 처리할 데이터가 들어 있다. 메시지 키와 메시지 값은 직렬화되어 브로커로 전송되기 때문에 컨슈머가 이용할 때는 직렬화한 형태와 동일한
형태로 역직렬화를 수행해야 한다. 레코드의 오프셋은 0 이상의 숫자로 이뤄져 있다. 레코드의 오프셋은 직접 지정할 수 없고 브로커에 저장될 때 이전에 전송된 레코드의
`오프셋 + 1` 값으로 생성된다. 오프셋은 카프카 컨슈머가 데이터를 가져갈 때 사용된다. 오프셋을 사용하면 컨슈머 그룹으로 이루어진 카프카 컨슈머들이 파티션의 데이터를
어디까지 가져갔는지 명확히 지정할 수 있다.

헤더는 레코드의 추가적인 정보를 담는 메타데이터 저장소 용도로 사용한다. 헤더는 키/값으로 데이터를 추가하여 레코드의 속성을 저장하여 컨슈머에서 참조할 수 있다.

## 카프카 클라이언트
카프카 클러스터에 명령을 내리거나 데이터를 송수신하기 위해서 카프카 클라이언트 라이브러리는 카프카 프로듀서, 컨슈머, 어드민 클라이언트를 제공하는 카프카 클라이언트를 사용해서
애플리케이션을 개발한다. 


### 프로듀서
카프카 데이터의 시작점이다. 필요한 데이터를 선언하고 브로커의 특정 토픽의 파티션에 전송한다. 프로듀서는 데이터를 전송할 때 리더 파티션을 가지고 있는 
카프카 브로커와 직접 통신한다. 

[Example](./producer/src/main/java/SimpleProducer.java)
```shell
 ./bin/kafka-topics.sh \
  --bootstrap-server \
  localhost:9092 \
  --create \
  --topic test \
  --partitions 3

# [main] INFO org.apache.kafka.clients.producer.ProducerConfig - ProducerConfig values:
# 	acks = 1
# 	batch.size = 16384
# 	bootstrap.servers = [192.168.0.11:9092]
# 	buffer.memory = 33554432
# 	client.dns.lookup = default
# 	client.id = producer-1
# 	compression.type = none
# 	connections.max.idle.ms = 540000
# 	delivery.timeout.ms = 120000
# 	enable.idempotence = false
# 	interceptor.classes = []
# 	key.serializer = class org.apache.kafka.common.serialization.StringSerializer
# 	linger.ms = 0
# 	max.block.ms = 60000
# 	max.in.flight.requests.per.connection = 5
# 	max.request.size = 1048576
# 	metadata.max.age.ms = 300000
# 	metadata.max.idle.ms = 300000
# 	metric.reporters = []
# 	metrics.num.samples = 2
# 	metrics.recording.level = INFO
# 	metrics.sample.window.ms = 30000
# 	partitioner.class = class org.apache.kafka.clients.producer.internals.DefaultPartitioner
# 	receive.buffer.bytes = 32768
# 	reconnect.backoff.max.ms = 1000
# 	reconnect.backoff.ms = 50
# 	request.timeout.ms = 30000
# 	retries = 2147483647
# 	retry.backoff.ms = 100
# 	sasl.client.callback.handler.class = null
# 	sasl.jaas.config = null
# 	sasl.kerberos.kinit.cmd = /usr/bin/kinit
# 	sasl.kerberos.min.time.before.relogin = 60000
# 	sasl.kerberos.service.name = null
# 	sasl.kerberos.ticket.renew.jitter = 0.05
# 	sasl.kerberos.ticket.renew.window.factor = 0.8
# 	sasl.login.callback.handler.class = null
# 	sasl.login.class = null
# 	sasl.login.refresh.buffer.seconds = 300
# 	sasl.login.refresh.min.period.seconds = 60
# 	sasl.login.refresh.window.factor = 0.8
# 	sasl.login.refresh.window.jitter = 0.05
# 	sasl.mechanism = GSSAPI
# 	security.protocol = PLAINTEXT
# 	security.providers = null
# 	send.buffer.bytes = 131072
# 	ssl.cipher.suites = null
# 	ssl.enabled.protocols = [TLSv1.2]
# 	ssl.endpoint.identification.algorithm = https
# 	ssl.key.password = null
# 	ssl.keymanager.algorithm = SunX509
# 	ssl.keystore.location = null
# 	ssl.keystore.password = null
# 	ssl.keystore.type = JKS
# 	ssl.protocol = TLSv1.2
# 	ssl.provider = null
# 	ssl.secure.random.implementation = null
# 	ssl.trustmanager.algorithm = PKIX
# 	ssl.truststore.location = null
# 	ssl.truststore.password = null
# 	ssl.truststore.type = JKS
# 	transaction.timeout.ms = 60000
# 	transactional.id = null
# 	value.serializer = class org.apache.kafka.common.serialization.StringSerializer
#
# [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka version: 2.5.0
# [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka commitId: 66563e712b0b9f84
# [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1710334011117
# [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: CihwpILxSJCziJY-haxLMg
# [main] INFO SimpleProducer - ProducerRecord(topic=test, partition=null, headers=RecordHeaders(headers = [], isReadOnly = true), key=null, value=testMsg, timestamp=null)
# // record 출력
# [main] INFO org.apache.kafka.clients.producer.KafkaProducer - [Producer clientId=producer-1] Closing the Kafka producer with timeoutMillis = 9223372036854775807 ms.
#
````
정상 적재가 됐다면 토픽을 확인해보자.

```shell
kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic test --from-beginning
##testMsg
```

### 프로듀서 중요 개념
프로듀서는 카프카 브로커를 데이터를 전송할 때 내부적으로 파티셔너, 배치 생성 단계를 거친다.
전송하고자 하는 데이터는 ProducerRecord 클래스를 통해서 생성했다. 더 적극적으로 파티션 번호를 지정하거나 타임스탬프, 메시지 키를 설정할 수도 있다.
레코드의 타임스탬프는 카프카 브로커에 저장될 때 브로커 시간을 기준으로 설정하지만 필요에 따라 레코드 생성 시간 또는 그 이전, 이후로 설정할 수도 있다.

KafkaProducer가 send()를 호출하면 ProducerRecord는 파티셔너(partitioner)에서 토픽이 어느 파티션으로 전송될 것인지 정해진다. KafkaProducer 인스턴스를
생성할 때 파티셔너를 지정하지 않으면 DefaultPartitioner로 설정되어 파티션이 정해진다. 파티셔너에 의해 구분된 레코드는 데이터를 전송하기 전에 accumulator에 
데이터를 버퍼로 쌓아놓고 발송한다. 이 버퍼는 배치로 묶어서 전송함으로써 카프카의 프로듀서 처리량을 향상시키는데 도움을 준다.

프로듀서 API를 사용하면 "UniformStickyPartitioner", "RoundRobinPartitioner" 2개의 파티션을 제공한다. 2.5.0에서는 파티셔너 지정이 없으면
"UniformStickyPartitioner"가 기본 설정된다. "UniformStickyPartitioner", "RoundRobinPartitioner" 둘 다 메시지 키가 있으면 메시지 키의
해시값과 파티션을 매칭하는 데이터를 전송한다는 점이 동일하다. 메시지 키가 없으면 파티션에 최대한 동하게 분배하는 로직이 있는데 "UniformStickyPartitioner"이
"RoundRobinPartitioner"의 개선판이라고 기억하면 된다.

RoundRobin은 파티션 순회가 기본이기에 배치로 묶이는 빈도가 낮아 성능 향상에 기대 폭이 좁다. 그래서 "UniformStickyPartitioner"는 accumulator에서 데이터가
배치로 모두 묶일 때까지 기다렸다 전송하므로 성능상 이점이 크다.

추가적으로 카프카 프로듀서는 압축 옵션으로 브로커로 전송 시 압축 방식을 정할 수 있는데 압축 옵션을 정하지 않으면 raw 상태로 전송된다. 압축은 gzip, snappy, lz4, zstd를 지원한다.
압축을 하면 네트워크 처리량에서 이득을 보지만 압축 해제 시 CPU, 메모리에서 손해를 보므로 적절하게 선택하는 것이 좋다.

### 프로듀서 주요 옵션

1. 필수 옵션
- bootstrap.servers : 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 `브로커의 호스트 이름: 포트`를 1개 이상 작성한다. 2개 이상 브로커 정보를 입력하여 일부 브로커에 이슈가 발생하더라도 접속하는 데 무리가 없도록 설정할 수 있다.
- key.serializer : 레코드에 키 직렬화 클래스를 지정한다. 
- value.serializer : 레코드의 메시지 값 직렬화 클래스를 지정한다.

2. 선택 옵션
- acks : 프로듀서가 전송한 데이터가 브로커로 정상 입력이 됐는지 확인하는데 사용하는 옵션이다. (1, 0 , -1(all)) 기본값은 1로 리더 파티션에 데이터가 저장되면 저장 성공으로 판단한다.
         0은 프로듀서가 전송한 즉시 브로커에 데이터 저장 여부와 상관 없이 성공으로 판단한다. -1 또는 all은 `min.insync.replicas` 개수에 해당하는 리더 파티션과 팔로워 파티션에
         데이터가 저장되면 성공하는 것으로 간주한다.
- buffer.memory : 브로커로 전송한 데이터를 배치로 모으기 위한 버퍼 메모리 양을 지정한다.
- retries : 프로듀서가 브로커로부터 에러를 받고 재전송 시도하는 횟수를 지정한다.
- batch.size : 배치로 전송할 레코드 최대 용량을 지정한다. 너무 작으면 자주 보내고 크면 메모리를 더 많이 사용한다.
- linger.ms : 배치 전송까지 기다리는 최소 시간이다.
- partitioner.class : 레코드를 파티션에 전송할 때 적용하는 파티셔너 클래스를 지정한다. `org.apahce.kafka.clients.producer.internals.DefualtPartitioner`
- enable.idempotence: 멱등성 프로듀서로 동작할지 설정한다.
- transactional.id : 프로듀서가 레코드를 전송할 때 레코드를 트랜잭션 단위로 묶을지 여부를 설정한다. 

key를 입력하면
```java
class Producer {
    public static void main(String[] args) {
        
        ProducerRecord<String, String> record = new ProducerRecord<>("test", "pangyo", "23");
        /**
         *  root@6b1197d09376:/# kafka-console-consumer.sh \
         *  --bootstrap-server localhost:9092 \
         *  --topic test \
         *  --property print.key=true \
         *  --property key.separator="-" \
         *  --from-beginning
         *  
         *  
         *  pangyo-testMsg
         *  null-testMsg
         */
        
        
        //파티션을 지정하고 싶다면
        ProducerRecord<String, String> record = new ProducerRecord<>(/*TOPIC_NAME, partitionNo, messageKey, messageValue*/ );
    }    
}

```

### 커스텀 파티셔너를 가지는 프로듀서
프로듀서 사용환경에 따라 특정 데이터를 가지는 레코드를 특정 파티션으로 보내야할 때가 있다. 기본 파티셔너를 사용하면 메시지키 해시 값으로 매칭하기에 어느 파티션으로 
전달되는지 정확히 할 수 없다. 이 떄 Partitioner 인터페이스를 사용해서 사용자 정의 파티셔너를 생성하면 pangyo라는 값을 가진 메시지 키에 대해서 무조건 파티션
0으로 지정할 수 있다.

[CustomPartitionerExample](./producer/src/main/java/CustomPartitionerProducer.java)

### 브로커 정상 전송 여부를 확인하는 프로듀서
KafkaProducer의 send()는 Future를 반환한다. RecordMetadata의 비동기 결과를 표현하는 것으로 ProducerRecord가 카프카 브로커에 정상적으로 적재되었는지에
대한 데이터가 포함되어 있다.

```shell
# [main] INFO org.apache.kafka.common.utils.AppInfoParser - Kafka startTimeMs: 1710418008987
# [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: CihwpILxSJCziJY-haxLMg
# [main] INFO SimpleProducer - METADATA test-0@2
```
정상적으로 적재되면 토픽 이름, 파티션 번호, 오프셋 번호가 출력된다.  그리나 동기로 프로듀서의 전송결과를 확인하는 것은 문제가 될 수 있다. 동기 처리를 하기 때문이다.
이 경우를 위해서 Callback 클래스가 따로 있다.

```java

 class Producer {
     public static void main(String[] args) {
         String messageValue = "testMsg";
         ProducerRecord<String, String> record = new ProducerRecord<>(TOPIC_NAME, "pangyo", messageValue);
        //messageKey는 null

         try {
             producer.send(record, new ProducerCallback());
             logger.info("--------------------------------");
             RecordMetadata metadata = producer.send(record).get();
             logger.info("METADATA {}", metadata);
         } catch (InterruptedException | ExecutionException e) {
             throw new RuntimeException(e);
         }
         producer.flush();
         producer.close();
     }
 }       
        
/**
 * [kafka-producer-network-thread | producer-1] INFO org.apache.kafka.clients.Metadata - [Producer clientId=producer-1] Cluster ID: CihwpILxSJCziJY-haxLMg
 * [main] INFO SimpleProducer - --------------------------------
 * [kafka-producer-network-thread | producer-1] INFO SimpleProducer - test-0@5
 * [main] INFO SimpleProducer - METADATA test-0@6
 */
```

결과를 보면 비동기로 진행됐음을 알 수 있다. 

-------------------------------

## 컨슈머 API
프로듀서가 전송한 데이터는 카프카 브로커에 적재된다. 컨슈머는 적재된 데이터를 사용하기 위해 브로커로부터 데이터를 가져와서 필요한 처리를 한다. 

### 카프카 컨슈머
컨슈머를 구현하는 가장 간단한 방법은 프로듀서처럼 자바 애플리케이션을 만드는 것이다. 기본 설정으로 생성할 수 있는 오토 커밋 카프카 컨슈머를 만들기 위해서는
프로듀서와 동일한 디펜던시로 구성하면 된다.

[Consumer](./consumer/src/main/java/SimpleConsumer.java)

```java
/**
 * 
 * [main] INFO org.apache.kafka.clients.consumer.KafkaConsumer - [Consumer clientId=consumer-test-group-1, groupId=test-group] Subscribed to topic(s): test
 * [main] INFO org.apache.kafka.clients.Metadata - [Consumer clientId=consumer-test-group-1, groupId=test-group] Cluster ID: CihwpILxSJCziJY-haxLMg
 * [main] INFO SimpleConsumer - ConsumerRecord(
 *                                              topic = test,
 *                                              partition = 0,
 *                                              leaderEpoch = 0,
 *                                              offset = 13,
 *                                              CreateTime = 1710419096928,
 *                                              serialized key size = 6,
 *                                              serialized value size = 7,
 *                                              headers = RecordHeaders(
 *                                                  headers = [],
 *                                                  isReadOnly = false
 *                                              ),
 *                                              key = pangyo,
 *                                              value = testMsg
 *                                           )
 */
```

### 컨슈머 중요 개념

토픽의 파티션으로부터 데이터를 가져가기 위해서 컨슈머를 운영하는 방법은 크게 2가지가 있다.

1. 1개 이상의 컨슈머로 이뤄진 컨슈머 그룹을 운영하는 것
2. 토픽의 특정 파티션만 구독하는 컨슈머를 운영하는 것

이렇게 두 가지가 있다. 
우선 1번의 경우 컨슈머를 각 컨슈머 그룹으로부터 격리된 환경에서 안전하게 운영할 수 있도록 도와주는 방식이다. 컨슈머 그룹으로 묶인 컨슈머들은 토픽의 1개 이상 파티션들에 할당되어 데이터를 가져갈 수 있다.
컨슈머 그룹으로 묶인 컨슈머가 토픽을 구독해서 데이터를 가져갈 때 1개 파티션은 최대 1개 컨슈머에 할당 가능하다. 반대로 1개 컨슈머는 여러 파티션에 할당될 수 있다. 
따라서 컨슈머 개수는 토픽의 파티션 개수보다 같거나 작아야 한다. 그렇지 않으면 컨슈머가 유휴 상태로 방치되게 된다.

컨슈머 그룹은 다른 컨슈머 그룹과 격리되는 특징을 가지고 있다. 따라서 카프카 프로듀서가 보낸 데이터를 각기 다른 역할을 하는 컨슈머 그룹끼리 영향을 받지 않게 
처리할 수 있다는 장점이 있다. 

만약 컨슈머 그룹에 장애가 생기면? 컨슈머 그룹으로 이뤄진 컨슈머 중 일부에 장애가 발생한 컨슈머에 할당한 파티션은 장애가 발생하지 않은 컨슈머에 소유권이 넘어가고
리밸런싱( rebalancing )을 진행한다.

리밸런싱은 두 가지 상황 아래서 발생하는데 `1. 새로운 컨슈머 추가되는 경우`, `2. 컨슈머가 제외되는 경우` 리밸런싱은 따로 코드를 작성해야 한다. 가용성을 높이면서
안정적 운영을 할 수 있도록 하는 리밸런싱은 일어날수록 손해다. 소유권 이전 때는 해당 컨슈머 그룹의 컨슈머들이 토픽의 데이터를 읽을 수 없기 때문이다. 
그룹 조정자(Group Coordinator)는 리밸런싱을 발동시키는 역할을 하는데 컨슈머 그룹의 컨슈머 변동을 감지한다. 브로커 중 하나가 이 역할을 수행한다. 

컨슈머는 카프카 브로커로부터 데이터를 어디까지 가져갔는지 커밋을 통해 기록한다. 특정 토픽의 파이션을 어떤 컨슈머 그룹이 몇 번째 가져갔는지 카프카 브로커 내부에서 
사용되는 내부 토픽()에 기록된다. 만약 컨슈머 동작 이슈가 발생해서 `__consumer_offsets`에 어디까지 읽어갔는지 오프셋 커밋이 기록되지 못했다면 중복처리가 될 수 있다. 
그러므로 데이터 처리의 중복이 발생하지 않도록 컨슈머 애플리케이션이 오프셋 커밋을 정상적으로 처리했는지 검증해야 한다. 

오프셋 커밋은 명시, 비명시적으로 수행할 수 있다. 기본 옵션은 `poll()` 메소드가 수행될 때 일정 간격마다 오프셋을 커밋하도록 `enable.auto.commit=true`로 설정되어 있다. 
이 옵션은 `auto.commit.interval.ms`에 설정된 값 이상을 지났을 때 그 시점까지 읽은 레코드의 오프셋을 커밋한다. `poll()` 메소드를 호출 될 때 커밋을 수행하므로 
코드상에서 따로 커밋 관련 코드를 쓸 필요는 없다. 비명시 오프셋 커밋은 편리하지만 `poll()` 이후 리밸런싱 또는 컨슈머가 강제 종료 될 경우 컨슈머가 처리하는 데이터가 
중복 혹은 유실될 수 있는 구조다. 그러므로 자동 커밋은 권장되지 않는다. 

명시적 commit은 `poll()`뒤에 반환받은 데이터 처리가 완료되고 `commitSync()`를 호출하면 된다. 그러면 poll()을 통해 반환된 레코드의 가장 마지막 오프셋을 기준으로
커밋을 수행한다. commitSync()는 브로커에 커밋 요청하고 커밋이 정상적으로 처리됐는지 응답까지 기다리는데 이는 컨슈머 처리량에 영향을 끼친다. 이를 해결하기 위해서 
`commitAsync()`를 호출하고 응답이 오기 전까지 데이터 처리를 수행할 수 있다. 하지만 비동기 커밋은 커밋 요청이 실패했을 때 현재 처리 중인 데이터의 순서를
보장할 수 없으며, 중복처리가 발생할 수도 있다. 

poll()을 하면 레코드들을 반환받지만 poll을 하는 시점에 클러스터에서 데이터를 가져오는 것은 아니다. 컨슈머 애플리케이션을 실행하게 되면 내부에서 `Fetcher` 인스턴스가
생성되어 poll() 메소드를 호ㅜㄹ하기 저네 미리 레코드들을 내부 큐로 가져온다. 이후에 사용자가 명시적으로 poll() 메소드를 호출하면 컨슈머는 내부 큐에 있는 레코드들을
반환받아 처리를 수행한다.


### 컨슈머 주요 옵션
1. 필수 옵션
- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 `hostName:port`를 한 개이상 작성한다. 2개를 입력하면 failover가 가능한 구조가 된다.
- key.deserializer
- value.deserializer

3. 선택 옵션
- group.id :  컨슈머 그룹 아이디를 지정한다. subscribe()로 토픽을 구독해서 사용할 떄느 이 옵션을 필수로 넣어야 한다.
- auto.offset.reset : 컨슈머 그룹이 특정 파티션을 읽을 때 저장된 컨슈머 오프셋이 없는 경우 어느 오프셋부터 읽을지 선택한는 옵션이다. 이미 컨슈머 오프셋이 있다면
                      이 옵션은 무시된다. [latest, earliest, none] 중 하나를 선택할 수 있다. latest는 가장 높은 오프셋(최근)부터 일긱 시작한다.
                      earliest로 설정하면 가장 낮은(오래전)부터 읽는다. none은 컨슈머 그룹이 커밋한 기록이 있는지 확인한다 없으면 에러 있으면 기존 커밋 기록 이후부터 읽는다.
                      기본 값은 latest

- enable.auto.commit : 자동/ 수동 커밋 여부를 선택한다. 기본은 true
- auto.commit.interval.ms : autocommit인 경우 오프셋 커밋 간격을 지정한다. 기본 값 5000(5s)
- max.poll.records : poll()로 반환되는 레코드 수를 정한다. 기본은 500
- session.timeout.ms : 컨슈머 - 브로커 간 연결이 끊기는 최대 시간이다. 이 시간 내로 heartbeat가 없으면 브로커는 컨슈머에 이슈가 발생했다고 판단, 리밸런싱한다. 기본 값은 10초
- heartbeat.interval.ms : 하트 비트를 전송하는 시간 간격이다. 기본 값 3초
- max.poll.interval.ms : poll() 메소드를 호출하는 간격의 최대 시간을 지정한다. poll 메소드 호출 이후 데이터를 처리하는데 너무 많은 시간이 걸리면 비정상으로 판단하고 리밸런싱을 진행한다. 기본값은 5분
- isolation.level : 트랜잭션 프로듀서가 레코드를 트랜잭션 단위로 보낼 경우 사용한다. 이 옵션은 `read_committed`, `read_uncommitted`로 설정할 수 있다. 
                    `read_committed`는 커밋 완료된 레코드만 읽는다. 기본 값은 `read_uncommitted`

### 도익 오프셋 커밋 
poll() 이후 commitSync()를 호출해서 오프셋 커밋을 명시적으로 수행할 수 있다. 

[SyncCommitExample](./consumer/src/main/java/SyncCommitConsumer.java)

```java
while ( true ) {
    ConsumerRecords<String , String > records = consumer.poll(Duration.ofSeconds(1));

    for ( ConsumerRecord<String, String> record: records) {
        logger.info("{}", record);
    }

    consumer.commitSync();
}
```

가장 마지막 레코드의 오프셋을 기준으로 커밋한다. 그렇기에 동기 오프셋 커밋을 사용할 경우 poll 메소드로 받은 모든 레코드의 처리가 끝난 후 `commitSync()`를 호출해야 한다. 
동기 커밋의 경우 브로커로 커밋을 요청한 이후 커밋이 완료될 때까지 기다린다. 브로커로부터 컨슈머 오프셋 커밋이 완료될 때까지 컨슈머는 데이터를 더 처리하지 않고
오토 커밋이나 비동기 커밋보다 동일 시간 당 데이터 처리량이 적다는 특징이 있다. 

`commitSync()`에 파라미터가 없으면 poll() 뒤 가장 마지막 레코드의 오프셋을 기준으로 커밋된다. 만약 개별 레코드 단위로 매번 오프셋을 커밋하고 싶다면,
`commitSync()`에 `Map<TopicPartition, OffsetAndMetadata>` 인스턴스를 파라미터로 넣으면 된다.

[SyncCommitEveryTimeExample](./consumer/src/main/java/SyncCommitEveryTimeConsumer.java)
```java
config.put(ConsumerConfig.ENABLE_AUTO_COMMIT_CONFIG, false);

... 
        
while ( true ) {
    ConsumerRecords<String , String > records = consumer.poll(Duration.ofSeconds(1));
    Map<TopicPartition, OffsetAndMetadata> currentOffset = new HashMap<>();

    for ( ConsumerRecord<String, String> record: records) {
        logger.info("{}", record);
        currentOffset.put(
                new TopicPartition(record.topic(), record.partition()),
                new OffsetAndMetadata(record.offset() + 1, null)
        );

        consumer.commitSync(currentOffset);
    }

}
```

### 비동기 오프셋 커밋
동기 처리는 역시 지연이 생기기 떄문에 비동기로 처리하는 방법도 있다. `commitAsync()`로 사용할 수 있다.

[AysncCommitConsumerExample](./consumer/src/main/java/AsyncCommitConsumer.java)

```java
while ( true ) {
    ConsumerRecords<String , String > records = consumer.poll(Duration.ofSeconds(1));

    for ( ConsumerRecord<String, String> record: records) {
        logger.info("{}", record);
    }

    consumer.commitAsync();
}
```
async도 동기와 마찬가지로 poll로 리턴된 가장 마지막 레코드를 기준으로 오프셋응ㄹ 커밋한다. 다만, 동기 오프셋 커밋과 다른 점은 커밋이 완료될 떄까지 응답을
기다리지 않는다는 것이다. 이 때문에 동기 오프셋 커밋을 사용할 때보다 동일 시간당 데이터 처리량이 더 많다.

```java
while ( true ) {
    ConsumerRecords<String , String > records = consumer.poll(Duration.ofSeconds(1));

    for ( ConsumerRecord<String, String> record: records) {
        logger.info("{}", record);
    }

    consumer.commitAsync();
}
```

`OffsetCommitCallback` 함수는 commitAsync()의 응답을 받을 수 있도록 도와주는 콜백 인터페이스이다. 함수는 commitAsync()의 응답을 받을 수 있도록
도와주는 콜백 인터페이스다. 비동기로 받은 커밋 응답은 onComplete() 메소드를 통해 확인할 수 있다. 정상적으로 커밋되었다면 Exception 변수는 null이고, 
커밋 완료된 오프셋 정보가 `Map<TopicPartition, OffsetAndMetadata>`에 포함되어 있다. 