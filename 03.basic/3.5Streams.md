## Kafka Streams
카프카 스트림즈는 토픽에 적재된 데이터를 상태 기반(Stateful) 또는 비상태 기반(Stateless)으로 실시간 변환하여 다른 토픽에 적재하는 라이브러리다. 카프카의
스트림 데이터 처리를 위해서 [아파치 스파크(Spark)](https://aws.amazon.com/ko/what-is/apache-spark/), [아파치 플링크(Flink)](https://aws.amazon.com/ko/what-is/apache-flink/), [아파치 스톰(Storm)](), [플루언트디(Fluentd)]()와 같은 다양한 오픈소스 애플리케이션이
존재하지만 카프카 스트림즈를 사용해야하는 이유가 뭘까? 스트림즈는 카프카에서 공식 지원하는 라이브러리다. 카프카 버전이 올라갈 때마다 스트림즈 라이브러리도 같이 릴리즈 된다.
그래서 카프카 클러스터와 호환성이 높으며 스트림즈 처리에 필요한 편리한 기능들(신규 토픽 생성, 상태 저장, 데이터 조인 등)을 제공한다. 
스트림즈 애플리케이션 또는 카프카 브로커의 장애가 발생해도 장애 허용 시스템(fault tolerant system)을 가지고 있어서 데이터 처리 안정성이 매우 뛰어나다.
카프카 클러스터를 운영하면서 실시간 스트림 처리를 해야하는 경우에 스트림즈 애플리케이션으로 개발하는 것을 고려할 만하다. 


스트림즈 애플리케이션은 내부적으로 쓰레드를 1개 이상 생성할 수 있으며, 쓰레드는 1개 이상의 태스크를 가진다. 스트림즈의 태스크는 스트림즈 애플리케이션을 실행하면
생기는 데이터 처리 최소 단위다. 만약, 3개의 파ㅣ션으로 이뤄진 토픽을 처리하는 스트림즈 애플리케이션을 실행하면 내부에 3개의 테스크가 생긴다. 컨슈머의 병렬 처리를 위해
컨슈머 그룹으로 이뤄진 컨슈머 쓰레드를 여러 개 실행하는 것과 비슷하다고 볼 수 있다. 카프카 스트림즈는 컨슈머 쓰레드를 늘리는 방법과 동일하게 병렬처리를 위해 파티션과
스트림즈 쓰레드(또는 프로세스) 개수를 늘림으로써 처리량을 늘릴 수 있다. (실제 운영 환경에서는 안정적 운영을 위해 2 개 이상의 서버로 구성하여 스트림즈 애플리케이션을 운영한다.)

카프카 스트림즈의 구조와 사용 방법을 알기 위해서 토폴로지(topology)와 관련된 개념을 익혀야 한다. 카프카 스트림즈에서는 토폴로지를 이루는 노드를 '프로세서'라고 부르고
간선을 '스트림'이라고 부른다. 스트림은 토픽의 데이터를 뜻하는데 프로듀서와 컨슈머에서 활용했던 렠hㅋ드와 동일하다. 프로세서에는 `소스 프로세서`, `스트림 프로세서`, `싱크 프로세서` 3가지가 있다.

1. 소스 프로세서 : 데이터를 처리하기 위해 최초로 선언해야 하는 노드, 하나 이상의 토픽에서 데이터를 가져오는 역할
2. 스트림 프로세서 : 다른 프로세서가 반환한 데이터를 처리하는 역할. 변환, 분기처리와 같은 로직이 데이터 처리의 일종이라고 볼 수 있다. 
3. 싱크 프로세서 : 데이터를 특정 카프카 토픽으로 저장하는 역할을 하며, 스트림즈로 처리된 최종 종착지


````
               🌕                => 소스 프로세서 
             ↙    ↘
           🌕       🌕           => 스트림 프로세서
             ↘    ↙   ↘
               🌕        🌕      => 스트림 프로세서
               ↓         ↓           
               🌕        🌕      => 싱크 프로세서
    
````

방식은 스트림즈DSL과 프로세서 API 2가지로 개발 가능하다. DSL로 변환 로직을 어렵지 않게 작성할 수 있지만 만약 DSL에 없는 기능의 경우 프로세서 API로 구현할 수 있다.

1. 스트림즈DSL로 구현하는 데이터 처리 예시
    - 메시지 값을 기반으로 토픽 분기 처리 
    - 지난 10분간 들어온 데이터 개수 집계
    - 토픽과 다른 토픽의 결합으로 새로운 데이터 생성
   
2. 프로세서 API로 구현하는 예시
    - 메시지 값의 종류에 따라 토픽을 가변적으로 전송
    - 일정한 시간 간격으로 데이터 처리 


### StreamsDSL
레코드의 흐름을 추상화한 3가지 개념인 KStream, KTable, GlobalKTable이 있다.


#### 1. KStream
KStream은 레코드 흐름을 표현한 것으로 메시지 키, 값으로 구성되어 있다. KStream으로 데이터를 조회하면 토픽에 존재하는 모든 레코드가 출력된다.
KStream은 컨슈머로 토픽을 구독하는 것과 동일한 선상에서 사용하는 것이라고 볼 수 있다. 

#### 2. KTable
KTable은 KStream과 다르게 메시지 키를 기준으로 묶어서 사용한다. KStream은 토픽의 모든 레코드를 조회할 수 있지만 KTable은 유니크한 메시지 키를 기준으로 
가장 최신 레코드를 사용한다. 그러므로 KTable로 데이터를 조회하면 메시지 키를 기준으로 가장 최신에 추가된 레코드의 데이터가 출력된다. 새로 데이터를 적재할 때 동일한 메시지 
키가 있을 경우 데이터가 업데이트 됐다고 볼 수 있다. 왜냐하면 메시지 키의 가장 최신 레코드가 추가됐기 떄문이다.

#### 3. GlobalKTable
GlobalKTable은 KTable과 동일하게 메시지 키를 기준으로 묶어서 사용된다. 그러나 KTable로 선언된 토픽은 1개 파티션이 1개 태스크에 할당되어 사용되고, GlobalKTable로 
선언된 토픽은 모든 파티션 데이터가 각 태스크에 할당되어 사용된다는 차이점이 있다. GlobalKTable을 설명하는 가장 좋은 예는 KStream, KTable이 데이터 Join을 
수행할 떄다. KStream, KTable을 조인하려면 co-partitioning되어 있어야 한다. co-partitioning이란 조인을 하는 2개 데이터의 파티션 개수가 동일하고 파티셔닝
전략을 동일하게 맞추는 작업이다. 파티션 개수가 동일하고 파티셔닝 전략이 같은 경우에는 동일한 메시지 키를 가진 데이터가 동일한 태스크에 들어가는 것을 보장한다. 
이를 통해 각 태스크는 KStream의 레코드와 KTable의 메시지 키가 동일한 경우 조인을 수행할 수 있다. 

조인을 수행하는 토픽들이 코파티셔닝되어 있음을 보장할 수 없다는 문제점이 있는데, KStream, KTable로 사용하는 2개의 토피기 파티션 개수가 다를 수도 있고
파티션 전략이 다를 수도 있다. 이런 경우 조인할 수 없다. 코파티셔닝이 되지 않은 2개의 토픽을 조인하는 로직이 담긴 스트림즈 애플리케이션을 실행하면
`TopologyException`이 발생한다. 

조인을 수행하는 KStream, KTable이 코파티셔닝 되어 있지 않으면 KStream, KTable을 repartitioning하는 과정을 거쳐야한다. repartitioning은 새로운 토픽에
새로운 메시지 키를 가지도록 재배열 하는 과정이다. 

co-partitioning이 되어 있지 않은 2개의 토픽을 조인하기 위해서는 repartitioning을 해야하고 이 과정은 토픽에 기존 데이터를 주복해서 생성할 뿐만 아니라
파티션을 재배열하기 위해 프로세싱하는 과정도 거쳐야 한다. 

이렇게 코파티셔닝되지 않은 KStream과 KTable을 조인해서 사용하고 싶다면 KTable을 GlobalKTable로 선언하여 사용하면 된다. GlobalKTable은 코파티셔닝되지 않은
KStream과 데이터 조인을 할 수 있다. 왜냐하면 KTable과 다르게 GlobalKTable로 정의된 데이터는 스트림즈 애플리케이션의 모든 태스크에 동일하게 공유되어 사용되기
떄문이다.

대신 GlobalKTable을 사용하면 태스크마다 GlobalKTable로 정의된 모든 데이터를 저장하고 사용하기 떄문에 스트림즈 애플리케이션 로컬 스토리지 사용량이 증가하고 네트워크, 브로커에 부하에 생기므로
가급적 필요한 경우에만 사용하는 것이 좋다. 그러므로 데이터 양이 많다면 repartitioning이 낫다. 

#### 주요 옵션
1. 필수 옵션
- bootstrap.servers: 프로듀서가 데이터를 전송할 대상 카프카 클러스터에 속한 브로커의 호스트이름:포트를 1개 이상 작성한다. 
- application.id : 스트림즈 애플리케이션을 구분하기 위한 고유 아이디를 설정한다. 다른 로직을 가진 스트림즈 애플리케이션들은 서로 다른 application.id를 가져야 한다.

2. 선택 옵션
- default.key.serde: 레코드의 메시지 키를 직렬, 역직렬화하는 클래스를 지정한다. 기본 값은 `Serdes.ByteArray().getClass.getName()`
- default.value.serde: 레코드 메시지 값을 직렬, 역직렬화하는 클래스를 지정한다. 기본 값은 `Serdes.ByteArray().getClass.getName()`
- num.stream.threads: 스트림 프로세싱 실행 시 실행될 쓰레드 개수를 지정한다. 기본 값은 1
- state.dir: rocksDB 저장소가위치할 디렉토리를 지정한다. rocksDB는 facebook기 개발한 고성은 key-value DB로 카프카 스트림즈가 상태기반 데이터 처리를 할 때 로컬 저장소로 사용한다. 기본 값은 /tmp/kafka-streams


####  스트림즈DSL - stream(), to()
스트림즈DSL로 구현할 수 있는 가장 간단한 스트림 프로세싱은 특정 토픽의 데이터를 다른 토픽으로 전달하는 것이다. 특정 토픽을 KStream 형태로 가져오려면 StreamsDSL의 stream()을 사용하면 된다. 
KStream 데이터를 특정 토픽으로 저장하려면 스트림즈DSL의 to()를 사용한다. 


[StreamsApplication](/streamsDSL/src/main/java/SimpleStreamApplication.java)

```java
public class SimpleStreamApplication {
    private final static Logger logger = LoggerFactory.getLogger(SimpleStreamApplication.class);
    private final static String APPLICATION_NAME = "streams-application";
    private final static String BOOTSTRAP_SERVER = "192.168.0.11:9092";
    private final static String STREAM_LOG = "stream_log";
    private final static String STREAM_LOG_COPY = "stream_log_copy";


    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        

        StreamsBuilder builder = new StreamsBuilder();
       /**
        * StreamsBuilder는 스트림 토폴리지를 정의하기 위한 용도로 사용된다.
        */
        KStream<String, String> streamLog = builder.stream(STREAM_LOG);
       /**
        * stream_log로 KStream 객체를 만들기 위해서 stream()를 사용했다. StreamBuilder는 stream()외에 KTable을 만드는
        * table(), GlobalKTabler을 만드는 globalTable() 메소드도 지원한다. 
        * 
        * stream(), table(), globalTable()은 최초의 토픽 데이터를 가져오는 소스 프로세서다. 
        */
        streamLog.to(STREAM_LOG_COPY);
       /**
        * stream_log를 담은 KStream 객체를 다른 토픽으로 전송하기 위해서 to()를 사용했다. to()는 KStream 인스턴스의 데이터들을
        * 특정 토픽으로 저장하기 위한 용도로 사용된다. 즉, to()는 싱크 프로세서다. 
        * 
        */

        KafkaStreams streams = new KafkaStreams(builder.build(), properties);
        streams.start();
       /**
        * SteramBuilder로 정의한 토폴로지에 대한 정보와 스트림즈 실행을 위한 기본 옵션을 파라미터로 KafkaStreams 인스턴스를 생성한다.
        * KafkaStreams 인스턴스를 실행하려면 `start()`를 사용하면 된다. 
        * 이 스트림즈 애플리케이션은 stream_log 토픽의 데이터를 stream_log_copy 토픽으로 전달한다. 
        */
    }
}
```

```shell
/bin/kafka-topics.sh --create \
--bootstrap-server localhost:9092 \
--partitions 3 \
--topic stream_log

#Created topic stream_log.
```
stream_log라는 토픽을 만든 후, streamApplication을 실행시키면 stream_log를 stream_log_copy로 복사해서 넘긴다. 
```shell
# producer
/bin/kafka-console-producer.sh --bootstrap-server localhost:9092 --topic stream_log
>hello
>kafka
>stream

# consumer
/bin/kafka-console-consumer.sh --bootstrap-server localhost:9092 --topic stream_log_copy --from-beginning
hello
kafka
stream
```

이와 같이 stream_log => stream_log_copy로 브로드캐스팅한다. 


#### StreamDSL-filter()
토픽으로 넘어온 데이터를 필터링할 수도 있다. `filter()` 메소드를 사용하면 된다. 

[FilterStream](/streamsDSL/src/main/java/SimpleStreamFilterApplication.java)
```java
public class SimpleStreamFilterApplication {
    private final static Logger logger = LoggerFactory.getLogger(SimpleStreamFilterApplication.class);
    private final static String APPLICATION_NAME = "streams-application";
    private final static String BOOTSTRAP_SERVER = "192.168.0.11:9092";
    private final static String STREAM_LOG = "stream_log";
    private final static String STREAM_LOG_COPY = "stream_log_copy";


    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        StreamsBuilder builder = new StreamsBuilder();
        KStream<String, String> streamLog = builder.stream(STREAM_LOG);
        KStream<String, String> filteredLog  = streamLog.filter((key, value) -> value.length() > 5);
        filteredLog.to(STREAM_LOG_COPY);

        KafkaStreams streams = new KafkaStreams(builder.build(), properties);
        streams.start();
    }
}
```

```shell
/bin/kafka-console-producer.sh \
--bootstrap-server localhost:9092 \
--topic stream_log
>hello
>kafka
>stream
>asd
>hello
>fiveCharacters
>

/bin/kafka-console-consumer.sh \
--bootstrap-server localhost:9092 \
--topic stream_log_copy \
--from-beginning

hello
kafka
stream
fiveCharacters
```
#### StreamsDSL-Ktable, KStream을 join()
KTable과 KStream은 메시지 키를 기준으로 조인할 수 있다. 대부분의 DB는 정적으로 저장된 데이터를 조인해서 사용하지만 카프카는 실시간으로 들어오는 데이터를 조인할 수 있다. 
예를 들어 이름을 메시지키, 수조를 메시지 값으로 가지고 있는 KTable이 있고 이름을 메시지키, 주문한 물품을 메시지 값으로 가지고 있는 KStream이 있다고 가정하자.
사용자가 물품을 주문하면 이미 토픽에 저장된 이름:주소로 구성된 KTable과 조인하여 물품과 주소가 조합된 데이터를 새로 생성할 수 있다.
사용자의 이벤트 데이터를 DB에 저장하지 않고도 조인하여 스트리밍 처리할 수 있다는 장점이 있다. 이를 통해 이벤트 기반 스트리밍 데이터 파이프라인을 구성할 수 있는 것이다.

KTable과 KStream을 조인할 떄 가장 중요한 것은 코파티셔닝이 되어 있는지 확인하는 것이다. 코파티셔닝이 되어 있지 않으면 `ToplogyException`이 발생하기 떄문이다. 그러므로
KTable을 사용할 토픽과 KStream으로 사용할 토픽을 생성할 떄 동일한 파티션 개수, 동일한 파티셔닝을 사용하는 것이 중요하다.
KTable로 사용할 토픽과 KStream으로 사용할 토픽을 만들 떄 둘 다 파티션을 3개로 동일하게 만든다. 파티셔닝 전량은 기본 파티셔너를 사용한다. 

```shell
/bin/kafka-topics.sh --create \
--bootstrap-server localhost:9092 \
--partitions 3 \
--topic address
Created topic address.

/bin/kafka-topics.sh --create \
--bootstrap-server localhost:9092 \
--partitions 3 \
--topic order
Created topic order.

/bin/kafka-topics.sh --create \
--bootstrap-server localhost:9092 \
--partitions 3 \
--topic order_join
Created topic order_join.
```
KTable이라고 다른 옵션을 추가해서 토픽을 생성하는게 아니다. Streams, Table, GlobalTable 모두 동일한 토픽이고, 스트림즈 내부에서 사용할 떄 메시지 키와 값을
사용하는 형태를 구분할 뿐인 것이다.

[KStreamJointKTable](/streamsDSL/src/main/java/KStreamJoinKTable.java)
```java

public class KStreamJoinKTable {
    private final static Logger logger = LoggerFactory.getLogger(SimpleStreamFilterApplication.class);
    private final static String APPLICATION_NAME = "streams-application";
    private final static String BOOTSTRAP_SERVER = "192.168.0.11:9092";
    private final static String ADDRESS_TABLE = "address";
    private final static String ORDER_TABLE = "order";
    private final static String ORDER_JOIN_TABLE = "order_join";

    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        StreamsBuilder builder = new StreamsBuilder();
        KTable<String, String> addressTable = builder.table(ADDRESS_TABLE);
        KStream<String, String> orderStream = builder.stream(ORDER_TABLE);

        orderStream.join(addressTable, (order, address) -> order + " send to " + address)
                .to(ORDER_JOIN_TABLE);

        KafkaStreams streams = new KafkaStreams(builder.build(), properties);
        streams.start();
    }
}
```
```shell
#producer_address
/bin/kafka-console-producer.sh \
--bootstrap-server localhost:9092 \
--topic address \
--property "parse.key=true" \
--property "key.separator=:"

#producer_order
/bin/kafka-console-producer.sh \
--bootstrap-server localhost:9092 \
--topic order \
--property "parse.key=true" \
--property "key.separator=:"


#consumer_order_join
/bin/kafka-console-consumer.sh \
--bootstrap-server localhost:9092 \
--topic order_join \
--property print.key=true \
--property key.separator=":" \
--from-beginning

```
> ! M1 이상에서 Streams가 3.2.0 이상이어야만 동작한다.( rocksDB 6.29.4.1 이상 ) 

추가로 KStream이 들어오면 키와 일치하는 마지막 KTable의 값을 찾아서 조인을 수행한다.  

#### StreamsDSL- GlobalKTable, KStream join()
코파티셔닝이 되어 있지 않을 경우
1. 리파티셔닝
2. KTable로 사용하는 토픽을 GlobalKTable로 선언하는 것이 있다.

```shell

/bin/kafka-topics.sh \
--create \
--bootstrap-server localhost:9092 \
--partitions 2 \
--topic address_v2

```
[GlobalKTableJoin](/streamsDSL/src/main/java/KStreamGlobalKTableJoin.java)
```java
public class KStreamGlobalKTableJoin {
    private final static Logger logger = LoggerFactory.getLogger(SimpleStreamFilterApplication.class);
    private final static String APPLICATION_NAME = "global-table-join-application";
    private final static String BOOTSTRAP_SERVER = "192.168.0.11:9092";
    private final static String ADDRESS_GLOBAL_TABLE = "address_v2";
    private final static String ORDER_TABLE = "order";
    private final static String ORDER_JOIN_TABLE = "order_join";

    public static void main(String[] args) {
        Properties properties = new Properties();
        properties.put(StreamsConfig.APPLICATION_ID_CONFIG, APPLICATION_NAME);
        properties.put(StreamsConfig.BOOTSTRAP_SERVERS_CONFIG, BOOTSTRAP_SERVER);
        properties.put(StreamsConfig.DEFAULT_KEY_SERDE_CLASS_CONFIG, Serdes.String().getClass());
        properties.put(StreamsConfig.DEFAULT_VALUE_SERDE_CLASS_CONFIG, Serdes.String().getClass());

        StreamsBuilder builder = new StreamsBuilder();
        GlobalKTable<String, String> addressTable = builder.globalTable(ADDRESS_GLOBAL_TABLE);
        KStream<String, String> orderStream = builder.stream(ORDER_TABLE);

        orderStream.join(addressTable, (orderKey, orderValue) -> orderKey,  (order, address) -> order + " send to " + address)
                .to(ORDER_JOIN_TABLE);

        KafkaStreams streams = new KafkaStreams(builder.build(), properties);
        streams.start();

    }
}
```

```shell
#producer_addres_v2
/bin/bash/kafka-console-producer.sh \
--bootstrap-server localhost:9092 \
--topic address_v2 \
--property "parse.key=true" \
--property "key.separator=:"

> somin:Busan
> wonyoung:Seoul


#producer_order
/bin/kafka-console-producer.sh \
--bootstrap-server localhost:9092 \
--topic order \
--property "parse.key=true" \
--property "key.separator=:"

> somin:Porsche
> wonyoung:BMW


#consumer_order_join
/bin/kafka-console-consumer.sh \
--bootstrap-server localhost:9092 \
--topic order_join \
--property print.key=true \
--property key.separator=":" \
--from-beginning

somin:Porsche send to Busan
wonyoung:BMW send to Seoul
```

겨로가물은 비슷해보이지만 GlobalKTable로 선언한 토픽은 토픽에 존재하는 모든 데이터를 태스크마다 저장하고 조인 처리한다는 점이 다르다. 그리고 조인을 수행할 때
KStream의 메시지 키뿐만 아니라 메시지 값을 기준으로도 매칭하여 조인할 수 있다는 점도 다르다.


### ProcessorAPI

프로세서API는 스트림즈DSL보다 투박하지만 토폴로지 기준으로 데이터를 처리한다는 관점에서는 동일한 역할을 한다.
스트림즈DSL은 데이터 처리, 분기, 조인을 위한 다양한 메소드들을 제공하지만 추가적인 상세 로직의 구현이 필요하다면 프로세서 API를 사용할 수도 있다.
프로세서 API에서는 스트림즈DSL에서 사용했던 KStream, KTable, GlobalKTable 개념이 없다. 


