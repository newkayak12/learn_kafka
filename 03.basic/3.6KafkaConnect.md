## 3.6 KafkaConnect
카프카 커넥트는 데이터 파이프라인 생성 시 반복 잡을 줄이고 효율적인 전송을 이루기 위한 애플리케이션이다. 파이프라인을 생성할 때 프로듀서, 컨슈머 애플리케이션을
만드는 것도 좋지만 반복적인 파이프 라인 생성 작업이 있을 때는 매번 프로듀서, 컨슈머를 개발하고 배포, 운영해야하기 때문에 비효율이다. 대신 커넥트는 특정 작업을
템플릿 형태로 만들어 놓은 커넥터를 실행함으로써 반복 작업을 줄일 수 있다. 파이프라인 생성 시 자주 반복되는 값들(토픽, 파일, 테이블 이름 등)을 파라미터로 받는
커넥터를 코드로 작성하면 이후 파이프 라인을 실행할 때는 코드 작성이 줄어들기 때문이다 .

커넥터는 프로듀서 역할인 `SourceConnector`, 컨슈머 역할인 `SinkConnector`로 나뉜다. 일정한 프로토콜을 가진 소스 애플리케이션이 싱크 애플리케이션이 있다면
커넥터를 통해 카프카로 데이터를 보내거나 카프카에서 데이터를 가져올 수 있다. MySQL, S3, MongoDB 등과 같은 저장소를 대표적인 싱크 애플리케이션, 소스 애플리케이션이라고
볼 수 있다. 즉, MySQL에서 카프카로 데이터를 보낼 때, 카프카에서 데이터를 MySQL로 저장 할 때 JDBC 커넥터를 사용해서 파이프라인을 생성할 수 있다. 

기본적으로 클러스터 간 토픽 미러링을 지원하는 미러메이커2 커넥터, 파일 싱크 커넥터, 파일 소스 커넥터를 기본으로 담고 있고(2.6 기준) 이외는 jar로 추가해서 사용하면
된다. 사용자가 커넥트에 커넥터 생성 명령을 내리면 커넥트는 내부에 커넥터와 태스크를 생성한다. 커넥터는 태스크들을 관리한다. 태스크는 커넥터에 종속되는 개념으로
실질적인 데이터 처리를 한다. 그렇기 떄문에 데이터 처리를 정상적으로 하는지 확인하기 위해서는 각 태스크의 상태를 확인해야 한다,

사용자가 커넥터를 이용해서 파이프라인을 생성할 때 `컨버터(Converter)`와 `트랜스폼(Transform)`을 추가할 수 있다. 커넥터를 운영할 때 필수 옵션은 아니다. 컨버터는 데이터 처리 전 스키마를 
변경하도록 도와준다. JsonConverter, StringConverter, ByteArrayConverter를 지원하고 필요하다면 커스텀 컨버터를 쓸 수도 있다.

트랜스폼은 데이터 처리 시 각 메시지 단위로 데이터를 간단하게 변환하기 위한 용도로 사용된다. 예를 들어 JSON 데이터를 커넥터에서 사용할 때 트랜스폼을 사용하면
특정 키를 삭제하거나 추가할 수 있다. Cas, Drop, ExtractField 등이 있다.


### 커넥트 실행
커넥트 실행은 두 가지 방법이 있다. 1. 단일모드(Standalone mode kafka connector), 2. 분산모드(Distributed mode kafka connector)가 있다.
단일 모드 커넥트는 단일 모드 애플리케이션으로 실행된다. 커넥터를 정의하는 파일을 작성하고 해당 파일을 참조하는 단일 모드 커넥트를 실행함으로써 파이프라인을 생성할 수 있다.
단일 모드는 1개 프로세스만 실행하는데 고가용성 구성이 되지 않아 단일 장애점(SPOF:Single Point Of Failure)이 될 수 있다.

반면 분산모드는 커넥트는 2대 이상의 서버에서 클러스터 형태로 운영함으로써 단일 모드 커넥트 대비 안전하게 운영할 수 있다는 장점이 있다. 2개 이상 커넥트가
클러스터로 묶에면 단일 장애점 문제를 해소할 수 있다. 또한 데이터 처리량의 변화에도 유연하게 대응할 수 있다. 커넥트가 실행되는 서버 개수를 늘림으로써 무중단으로
스케일아웃해서 처리량을 늘릴 수 있기 때문이다.

REST API로 커넥터 플러그인 종류, 태스크 상태, 커넥터 상태 등을 조회할 수 있다. 기본 포트는 8083이다.

| Method | Endpoint                                          | Description            |
|:------:|:--------------------------------------------------|:-----------------------|
|  GET   | /                                                 | 실행중인 커넥트 정보 확인         |
|        | /connectors                                       | 이름 확인                  |
|        | /connectors/{connectorName}                       | 정보 확인                  |
|        | /connectors/{connectorName}/config                | 설정 값 확인                |
|        | /connectors/{connectorName}/status                | 상태 값 확인                |
|        | /connectors/{connectorName}/tasks                 | 태스크 정보 확인              |
|        | /connectors/{connectorName}/tasks/{taskId}/status | 태스크 상태 확인              |
|        | /connectors/{connectorName}/topics                | 커넥터별 연동된 토픽 정보 확인      |
|        | /connector-plugins/                               | 커넥트에 존재하는 커넥터 플러그인 확인  |
|  POST  | /connectors                                       | 새로운 커넥터 생성 요청          |
|        | /connectors/{connectorName}/restart               | 커넥터 재시작 요청             |
|        | /connectors/{connectorName}/task/{taskId}/restart | 커넥터의 태스크 재시작 요청        |
|  PUT   | /connectors/{connectorName}/config                | 실행 중인 커넥터 설정 값 변경 요청   |
|        | /connectors/{connectorName}/pause                 | 커넥터 일시 중지 요청           |
|        | /connectors/{connectorName}/resume                | 커넥터 재개 요청              |
|        | /connector-plugins/{pluginName}/config/validate   | 커넥터 생성 시 설정 값 유효 여부 확인 |
| DELETE | /connectors/{connectorName}                       | 커넥터 종료                 |


### 단일 커넥트
```yaml
#connect-standalone.properties
bootstap.server=localhost:9092
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false
offset.storage.file.filename=/tmp/connect.offsets
offset.flush.interval.ms=10000
plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors, # 플러그인 많으면 , 로 구분

#connect-file-source.properties 
name=local-file-source
connector.class=FileStreamSource
tasks.max=1
file=test.txt
topic=connect-test
```
```shell
connect-standalone.sh \
/opt/kafka/config/connect-standalone.properties \
/opt/kafka/config/connect-file-source.properties
```

### 분산 모드
```yaml
#connector-distributed.properties
bootstrap.servers=localhost:9092
group.id=connect-cluster
key.converter=org.apache.kafka.connect.json.JsonConverter
value.converter=org.apache.kafka.connect.json.JsonConverter
key.converter.schemas.enable=false
value.converter.schemas.enable=false

offset.storage.topic=connect-offsets
offset.storage.replication.factor=1
config.storage.topic=connect-configs
config.storage.replication.factor=1
status.storage.topic=connect-status
status.storage.replication.factor=1
offset.flush.interval.ms=10000
plugin.path=/usr/local/share/java,/usr/local/share/kafka/plugins,/opt/connectors,
```
```shell
connect-distributed.sh \
/opt/kafka/config/connect-distributed.properties 
```

결과를 확인해보면?
```shell
curl GET http://localhost:8083/connector-plugins
[
  {"class":"org.apache.kafka.connect.file.FileStreamSinkConnector","type":"sink","version":"2.8.1"},
  {"class":"org.apache.kafka.connect.file.FileStreamSourceConnector","type":"source","version":"2.8.1"},
  {"class":"org.apache.kafka.connect.mirror.MirrorCheckpointConnector","type":"source","version":"1"},
  {"class":"org.apache.kafka.connect.mirror.MirrorHeartbeatConnector","type":"source","version":"1"},
  {"class":"org.apache.kafka.connect.mirror.MirrorSourceConnector","type":"source","version":"1"}
] 
```

## 소스 커넥터
소스 커넥터는 소스 애플리케이션 또는 소스 파일로부터 데이터를 가져와 토픽으로 넣는 역할을 한다. 오픈소스 커넥터를 사용해도 되지만 여타 문제 때문에 직접 개발해야 하는 
경우도 있는데 이 때는 카프카 커넥트 라이브러리에서 제공하는 `SourceConnector`, `SourceTask`를 이용해서 직접 소스 커넥터를 구현하면 된다. jar로 빌드해서 플러그인으로 
추가하면 된다.

소스 커넥터를 만들 떄 SourceConnector, SourceTask를 구현하면 된다. 전자는 태스크 실행 전 커넥터 설정 파일을 초기화하고 어떤 태스크 클래스를 사용할지 정의할 때 쓴다.
후자는 데이터를 실제로 핸들링하는 클래스다.SourceTask의 특이한 점은 토픽에서 사용하는 오프셋이 아닌 자체 오프셋을 사용한다는 점이다. SourceTask에서 사용하는
오프셋은 소스 애플리케이션 또는 소스 파일을 어디까지 읽었는지 저장하는 역할을 한다. 이 오프셋으로 데이터를 중복해서 토픽으로 보내는 것을 방지할 수 있다.

```java
public class TestSourceConnector extends SourceConnector {
    //SourceConnector를 상속한다.
    @Override
    public void start(Map<String, String> props) {
        //json 혹은 config로 입력한 값 초기화하느 메소드
        //올바른 값이 아니라면 ConnectionException으로 처리할 수 있다. 

    }

    @Override
    public Class<? extends Task> taskClass() {
        // 이 커넥터가 사용할 태스크 클래스 지정
        return null;
    }

    @Override
    public List<Map<String, String>> taskConfigs(int maxTasks) {
        //여기서 태스크마다 다른 설정 값을 줄 수도 있다.
        return null;
    }

    @Override
    public void stop() {
        //커넥터 종료 로직

    }

    @Override
    public ConfigDef config() {
        //커넥터가 사용할 설정 값에 대한 정보를 받는다.
        return null;
    }

    @Override
    public String version() { // 플러그인 버전
        return null;
    }
}
```

[SimpleSourceConnector](/connector/src/main/java/SimpleSourceConnector.java)
[SingleFileConnectorConfig](/connector/src/main/java/SingleFileConnectorConfig.java)
[SingleFileSourceTask](/connector/src/main/java/SingleFileSourceTask.java)

이후 jar로 뽑아서 plugin에 추가하면 된다.

### 싱크 커넥터
싱크 커넥터는 토픽의 데이터를 타겟 애플리케이션 또는 타겟 파일로 저장하는 역할을 한다. 

[SingleFileSinkConnector](/connector/src/main/java/SingleFileSinkConnector.java)
[SingleFileSinkConnectorConfig](/connector/src/main/java/SingleFileSinkConnectorConfig.java)
[SingleFileSinkTask](/connector/src/main/java/SingleFileSinkTask.java)
