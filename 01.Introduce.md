# Kafka

Apache Kafka는 실시간으로 기록 스트림을 게시, 구독, 저장 및 처리할 수 있는 분산형 데이터 스트리밍 플랫폼입니다.
여러 소스에서 데이터 스트림을 처리하고 여러 사용자에게 전달하도록 설계되었습니다.

간단히 말해 A지점에서 B지점까지 이동하는 것뿐만 아니라 A지점에서 Z지점을 비롯해 필요한 모든 곳에서 대규모 데이터를 동시에 이동할 수 있습니다.
즉, 카프카로 데이터 흘려 넣으면 카프카를 타고 원하는 애플리케이션에서 이를 가져가는 방식으로 동작한다. 

카프카는 ByteArray로 Serialize, Deserialize 하기 때문에 어떤 형식의 데이터도 흘려보낼 수 있다.

## 주요 특징
1. 높은 처리량
 카프카는 프로듀서가 브로커로 데이터를 보낼 때 컨슈머가 브로커로부터 데이터를 받을 떄 모두 묶어서 전송한다.

2. 확장성
  카프카는 데이터가 적을 때는 카프카 클러스터의 브로커를 최소한의 개수로 운영하다가 데이터 많아지면 scale-out해서 운영할 수 있다.

3. 영속성
  카프카는 전송받은 데이터를 메모리에 저장하지 않고 파일 시스템에 저장한다. OS 레벨에서 파일 시스템을 최대한 활용하는 방법을 적용했다. 
  OS에서 I/O 성능 향상을 위해서 페이징 캐시 영역을 메모리에 저장시켰다가 사용하기에 카프카가 파일 시스템에 저장하고 데이터를 저장, 전송하더라도
  처리량이 높은 것이다 .

4. 고가용성
  클러스터로 이뤄진 카프카는 데이터 복제를 통해서 고가용성의 특징을 가지게 됐다. 

## 카프카 브로커 힙 메모리 설정
카프카 브로커를 실행하기 위해서 힙 메모리 설정이 필요하다. 카프카 브로커는 레코드의 내용은 페이지 캐시로 시스템 메일리를 사용하고 나머지 객체들을 힙 메모리에 저장하여 사용한다.
이러한 특징으로 카프카 브로커를 운영할 떄 힙 메모리를 5GB 이상으로 설정하지 않는 것이 일반적이다.

```shell
export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"
echo $KAFKA_HEAP_OPTS

## 이러면 해당 세션에

vi ~/.bashrc
export KAFKA_HEAP_OPTS="-Xmx400m -Xms400m"

## 이러면 bash 환경설정
```

카프카 실행 shell을 보면
```shell
bash-5.2# cat kafka-server-start.sh 
#!/bin/bash
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

if [ $# -lt 1 ];
then
        echo "USAGE: $0 [-daemon] server.properties [--override property=value]*"
        exit 1
fi
base_dir=$(dirname $0)

if [ "x$KAFKA_LOG4J_OPTS" = "x" ]; then
    export KAFKA_LOG4J_OPTS="-Dlog4j.configuration=file:$base_dir/../config/log4j.properties"
fi

if [ "x$KAFKA_HEAP_OPTS" = "x" ]; then  ### $KAFKA_HEAP_OPTS가 있으면
    export KAFKA_HEAP_OPTS="-Xmx1G -Xms1G" ### 없으면
fi

EXTRA_ARGS=${EXTRA_ARGS-'-name kafkaServer -loggc'}

COMMAND=$1
case $COMMAND in
  -daemon)  ### -daemon 옵션으로 background foreground 설정할 수 있다.
    EXTRA_ARGS="-daemon "$EXTRA_ARGS
    shift
    ;;
  *)
    ;;
esac

exec $base_dir/kafka-run-class.sh $EXTRA_ARGS kafka.Kafka "$@"
```

## 브로커 실행 옵션 설정
config에 `server.properties` 에 카프카 브로커가 클러스터 운영에 필요한 옵션들을 지정할 수 있다.

```properties
broker.id = 0 
# 실행하는 카프카 브로커의 번호 (클러스터 구축 시 Unique 값 id가 충돌하면 비정상 동작)
listeners = PLAINTEXT://:9092
# 카프카 브로커가 통신을 위해서 열어둘 인터페이스 IP, port, 프로토콜을 설정할 수 있다. 기본 값은 모든 IP, port
advertised.listeners = PLAINTEXT://localhost:9092
# 카프카 클라이언트 또는 커맨드 라인에 접속할 때 사용하는 IP, port
listener.security.protocol.map = PLAINTEXT:PLAINTEXT,SSL:SSL,SASL_PLAINTEXT:SASL_PLAINTEXT,SASL_SSL:SASL_SSL
# SASL_SSL, SASL_PLAIN 보안 설정 시 프로토콜 매핑을 위한 설정
num.network.threads=3
# 네트워크를 통한 처리를 할 떄 사용할 네트워크 쓰레드 개수 설정 
num.io.threads=8
# 브로커 내부에서 사용할 쓰레드 개수
log.dirs = /tmp/kafka-logs
# 통신을 통해 가져온 데이터를 파일로 저장할 디렉토리 위치 ( 디렉토리가 없으면 문제가 생기니 실행 전 디렉토리 확인을 한다.)
num.partitions = 1
# 파티션 개수를 명시하지 않고 토픽을 생성할 때 기본 설정되는 파티션 수, 파티션 개수가 많아지면 병렬처리 데이터 양이 늘어난다.
log.retention.hours = 168
# 브로커가 저장한 파일이 삭제되기까지 걸리는 시간 log.retention.ms로 설정할 수도 있다. log.retention.ms -1로 설정하면 영원히 삭제되지 않는다.
log.segment.bytes = 1073741824
# 브로커가 저장할 파일의 최대 크기, 이 크기를 넘기면 새로운 파일이 생성된다.
zookeeper.connect = localhost:2181
# 연동할 주키퍼의 IP, port를 설정한다. 
zookeeper.connection.timout.ms=18000
# 주키퍼 세션 타임아웃 시간을 지정
```

## 주키퍼 실행
카프카 바이너리가 포함된 폴더에 주키퍼가 동봉돼 있다. 분산 코디네이션을 제공하는 주키퍼는 카프카 클러스터 설정 리더 정보, 컨트롤러 정보를 담고 있어 카프카를 
실행하는 데 필수 애플리케이션이다. 보통 3대 이상의 서버로 구성해서 사용하지만 한 서버에서 주키퍼, 카프카를 동시에 1대만 실행시켜 사용할 수 있다. 
이를 `Quick-and-dirty single-node`라고 부른다. 즉, 보통 주키퍼를 하나만으로 사용하지 않는다는 소리다. `bin/zookeeper-server-start.sh`로 
주키퍼를 백그라운드에서 실행할 수 있다. 주키퍼가 정상적으로 실행됐는지는 jps 명령어로 확인할 수 있다. jps는 JVM프로세스 상태를 보는 도구로서 JVM 위에서 동작하는
주키퍼 프로세스를 확인할 수 있다. `-m`로 main에 전달된 인자를 확인할 수 있고, `-v`으로 JVM에 전달된 인자를 함께 확인할 수 있다.

```shell
bash-5.2# ./bin/zookeeper-server-start.sh -daemon config/zookeeper.properties
bash-5.2# jps -vm

  885 Jps -vm -Dapplication.home=/usr/lib/jvm/java-17-amazon-corretto.aarch64 -Xms8m -Djdk.module.main=jdk.jcmd
  
  ###### https://velog.io/@hanblueblue/GC-2.-G1GC-tuning
  858 QuorumPeerMain config/zookeeper.properties \ 
      -Xmx400m \
      -Xms400m  \
      -XX:+UseG1GC \
      -XX:MaxGCPauseMillis=20 \ 
      -XX:InitiatingHeapOccupancyPercent=35 \ 
      -XX:+ExplicitGCInvokesConcurrent \
      -XX:MaxInlineLevel=15 \
      -Djava.awt.headless=true \
      -Xlog:gc*:file=/home/kafka/kafka_2.12-2.5.0/bin/../logs/zookeeper-gc.log:time,tags:filecount=10,filesize=102400 \
      -Dcom.sun.management.jmxremote \
      -Dcom.sun.management.jmxremote.authenticate=false \
      -Dcom.sun.management.jmxremote.ssl=false \
      -Dkafka.logs.dir=/home/kafka/kafka_2.12-2.5.0/bin/../logs -Dlog4j.configuration=file:./bin/../config/log4j.properties
```


> JPS ( Java Virtual Machine Process Status Tool)
> jps 명령어는 JVM 목록을 보여준다. 
> jps - : 전체 패키지 목록
> jps -m : 메인 메소드 args 목록
> jps -v : jvm 파라미터
> 

## 카프카 브로커 실행 및 로그 확인 
`-daemon` 옵션과 함께 카프카 브로커를 백그라운드 모드로 실행할 수 있다. 
```shell
bash-5.2# ./bin/kafka-server-start.sh -daemon config/server.properties
bash-5.2# jps -m 

  1333 Jps -m
  858 QuorumPeerMain config/zookeeper.properties
  1261 Kafka config/server.properties

bash-5.2# tail -f logs/server.log
```

## 카프카 통신 확인
카프카 정상 동작 여부를 확인하는 가장 쉬운 방법은 카프카 브로커 정보를 요청하는 것이다. 카프카 바이너리 패키지는 카프카 브로커에 대한 정보를 가져올 수 있는
`kafka-broker-api-versions.sh`를 명령어를 제공한다. 
```shell
bash-5.2# ./bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092
5722ad92016b:9092 (id: 0 rack: null) -> (
        Produce(0): 0 to 8 [usable: 8],
        Fetch(1): 0 to 11 [usable: 11],
        ListOffsets(2): 0 to 5 [usable: 5],
        Metadata(3): 0 to 9 [usable: 9],
        LeaderAndIsr(4): 0 to 4 [usable: 4],
        StopReplica(5): 0 to 2 [usable: 2],
        UpdateMetadata(6): 0 to 6 [usable: 6],
        ControlledShutdown(7): 0 to 3 [usable: 3],
        OffsetCommit(8): 0 to 8 [usable: 8],
        OffsetFetch(9): 0 to 7 [usable: 7],
        FindCoordinator(10): 0 to 3 [usable: 3],
        JoinGroup(11): 0 to 7 [usable: 7],
        Heartbeat(12): 0 to 4 [usable: 4],
        LeaveGroup(13): 0 to 4 [usable: 4],
        SyncGroup(14): 0 to 5 [usable: 5],
        DescribeGroups(15): 0 to 5 [usable: 5],
        ListGroups(16): 0 to 3 [usable: 3],
        SaslHandshake(17): 0 to 1 [usable: 1],
        ApiVersions(18): 0 to 3 [usable: 3],
        CreateTopics(19): 0 to 5 [usable: 5],
        DeleteTopics(20): 0 to 4 [usable: 4],
        DeleteRecords(21): 0 to 1 [usable: 1],
        InitProducerId(22): 0 to 3 [usable: 3],
        OffsetForLeaderEpoch(23): 0 to 3 [usable: 3],
        AddPartitionsToTxn(24): 0 to 1 [usable: 1],
        AddOffsetsToTxn(25): 0 to 1 [usable: 1],
        EndTxn(26): 0 to 1 [usable: 1],
        WriteTxnMarkers(27): 0 [usable: 0],
        TxnOffsetCommit(28): 0 to 3 [usable: 3],
        DescribeAcls(29): 0 to 2 [usable: 2],
        CreateAcls(30): 0 to 2 [usable: 2],
        DeleteAcls(31): 0 to 2 [usable: 2],
        DescribeConfigs(32): 0 to 2 [usable: 2],
        AlterConfigs(33): 0 to 1 [usable: 1],
        AlterReplicaLogDirs(34): 0 to 1 [usable: 1],
        DescribeLogDirs(35): 0 to 1 [usable: 1],
        SaslAuthenticate(36): 0 to 2 [usable: 2],
        CreatePartitions(37): 0 to 2 [usable: 2],
        CreateDelegationToken(38): 0 to 2 [usable: 2],
        RenewDelegationToken(39): 0 to 2 [usable: 2],
        ExpireDelegationToken(40): 0 to 2 [usable: 2],
        DescribeDelegationToken(41): 0 to 2 [usable: 2],
        DeleteGroups(42): 0 to 2 [usable: 2],
        ElectLeaders(43): 0 to 2 [usable: 2],
        IncrementalAlterConfigs(44): 0 to 1 [usable: 1],
        AlterPartitionReassignments(45): 0 [usable: 0],
        ListPartitionReassignments(46): 0 [usable: 0],
        OffsetDelete(47): 0 [usable: 0]
)

```


[docker-compose](kafka-compose.yml)